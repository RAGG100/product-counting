{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b22df79",
   "metadata": {
    "id": "5b22df79"
   },
   "source": [
    "# PIA\n",
    "Proyecto para verificar el correcto despacho de ordenes de marketplaces (Amazon, Mercado Libre) mediante métodos de computación visual (*Object counting*) con una version afinada de *YOLO*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a436b",
   "metadata": {
    "id": "922a436b"
   },
   "source": [
    "## Entrenamiento de modelo\n",
    "Hay dos maneras en que se planea obtener datos (dependiendo del tiempo que se disponga):\n",
    "1. **Post-despacho**\n",
    "    - Obtener imagenes de ordenes mediante ERP\n",
    "    - Obtener detalles de las órdenes mediante reportes de plataformas\n",
    "2. **Real time**\n",
    "    - Obtener imágenes con empleo de cámara\n",
    "    - Obtener detalles de las órdenes mediante petición a API de plataformas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f6eb1",
   "metadata": {
    "id": "a21f6eb1"
   },
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6a83df",
   "metadata": {
    "id": "ce6a83df"
   },
   "outputs": [],
   "source": [
    "# Para conexion con ERP\n",
    "import xmlrpc.client\n",
    "# Para extraer imagenes\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b697d",
   "metadata": {
    "id": "793b697d"
   },
   "source": [
    "### Peticióna a ERP\n",
    "Se realizará una conexión a la API del ERP que emplea la empresa y se obtendrán las ultimas imágenes tomadas a cada pedido e informacion del contenido de cada pedido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63910fac",
   "metadata": {
    "id": "63910fac"
   },
   "outputs": [],
   "source": [
    "# Información de acceso\n",
    "with open('./secrets/access_keys.json') as file:\n",
    "    db_info = json.load(file)\n",
    "\n",
    "# Autenticación\n",
    "common = xmlrpc.client.ServerProxy('{}/xmlrpc/2/common'.format(db_info['url']))\n",
    "uid = common.authenticate(db_info['db'], db_info['user'], db_info['password'], {})\n",
    "# Conexión con base de datos\n",
    "models = xmlrpc.client.ServerProxy('{}/xmlrpc/2/object'.format(db_info[\"url\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e21d6",
   "metadata": {
    "id": "ba4e21d6"
   },
   "outputs": [],
   "source": [
    "# Obtener imagenes creadas\n",
    "limite = 100\n",
    "fields = ['res_id', 'res_name', 'datas']\n",
    "filters = [\n",
    "    ['&',\n",
    "        ('create_date', '>=', '2025-10-14'), # Creadas despues de una fecha\n",
    "        ('res_model', '=', 'sale.order'), # Adjuntos a modelo de ventas\n",
    "        ('mimetype', '=', 'image/jpeg') # Tipo de archivo: imagenes\n",
    "    ]\n",
    "]\n",
    "attachments = models.execute_kw(db_info['db'], uid, db_info['password'], 'ir.attachment', 'search_read', filters, {'fields': fields, 'limit': limite})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce13a3",
   "metadata": {
    "id": "12ce13a3"
   },
   "outputs": [],
   "source": [
    "## Lista de ordenes asociadas a imagenes\n",
    "orders = [file.split('.')[0] for file in os.listdir('./training_data/labels') if file.endswith('.txt')]\n",
    "\n",
    "# Obtener ventas asociadas\n",
    "fields = ['name', 'order_line']\n",
    "filters = [[(\"name\", \"in\", orders)]]\n",
    "sales = models.execute_kw(db_info['db'], uid, db_info['password'], 'sale.order', 'search_read', filters, {'fields': fields})\n",
    "## Lista de lineas de las ordenes\n",
    "lines = [line for record in sales for line in record['order_line']]\n",
    "\n",
    "# Obtener lineas de la orden\n",
    "fields = ['product_id', 'product_uom_qty']\n",
    "filters = [[(\"id\", \"in\", lines)]]\n",
    "order_lines = models.execute_kw(db_info[\"db\"], uid, db_info['password'], 'sale.order.line', 'search_read', filters, {'fields': fields})\n",
    "\n",
    "# Obtener kits de productos\n",
    "## Kits\n",
    "fields = ['product_tmpl_id', 'bom_line_ids']\n",
    "filters = []\n",
    "kits = models.execute_kw(db_info[\"db\"], uid, db_info['password'], 'mrp.bom', 'search_read', filters, {'fields': fields})\n",
    "## Componentes de kits\n",
    "fields = ['product_id', 'product_qty']\n",
    "filters = []\n",
    "components = models.execute_kw(db_info[\"db\"], uid, db_info['password'], 'mrp.bom.line', 'search_read', filters, {'fields': fields})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67c5bc",
   "metadata": {
    "id": "fe67c5bc"
   },
   "source": [
    "### Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0508ace2",
   "metadata": {
    "id": "0508ace2",
    "outputId": "06c64bff-e4bc-4f60-98e4-9e569631ca4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes de solicitud\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Obtener imagenes creadas\n",
    "limite = 100\n",
    "fields = ['res_id', 'res_name', 'datas']\n",
    "ventas = [img.split('.')[0] for img in os.listdir('./datasets/training_data/labels')]\n",
    "#ids =\n",
    "ids = []\n",
    "with open('ids.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        ids.append(line[:-1])\n",
    "filters = [\n",
    "    [\n",
    "#     '&',\n",
    "#     '&',\n",
    "#        ('res_name', 'in', ventas), # Creadas despues de una fecha\n",
    "        ('res_id', 'in', ids), # Creadas despues de una fecha\n",
    "#        ('mimetype', '=', 'image/jpeg'), # Tipo de archivo: imagenes\n",
    "#        ('res_model', '=', 'sale.order'), # Adjuntos a modelo de ventas\n",
    "    ]\n",
    "]\n",
    "print(\"Antes de solicitud\")\n",
    "attachments = models.execute_kw(db_info['db'], uid, db_info['password'], 'ir.attachment', 'search_read', filters, {'fields': fields, 'limit': limite})\n",
    "print(len(attachments))\n",
    "# Guardar imagenes\n",
    "for record in attachments:\n",
    "    image = Image.open(io.BytesIO(base64.b64decode(record['datas'])))\n",
    "    if image.size[0] > image.size[1]:\n",
    "        image = image.rotate(-90, expand=True)\n",
    "    image.save(f'./datasets/training_data/images/{record['res_name']}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e962d7",
   "metadata": {
    "id": "02e962d7"
   },
   "source": [
    "Guardar las imagenes en una carpeta y rotar en caso de ser necesario para mantener proporciones adecuadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70ca4c",
   "metadata": {
    "id": "3b70ca4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guardar imagenes\n",
    "for record in attachments:\n",
    "    image = Image.open(io.BytesIO(base64.b64decode(record['datas'])))\n",
    "    if image.size[0] > image.size[1]:\n",
    "        image = image.rotate(-90, expand=True)\n",
    "    image.save(f'./images/{record['res_name']}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21c557",
   "metadata": {
    "id": "0a21c557"
   },
   "source": [
    "De los datos obtenidos calcular la cantidad de productos por venta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a23e6e",
   "metadata": {
    "id": "d9a23e6e"
   },
   "outputs": [],
   "source": [
    "# Utilidad\n",
    "def extract_sku(name: str) -> str:\n",
    "    return re.match(r'\\[(.*)\\]', name).group(1)\n",
    "\n",
    "# Paquetes\n",
    "# Obtener paquetes y sus componentes\n",
    "kits_df = pd.DataFrame.from_records(kits)\n",
    "kits_df.loc[:,'product_tmpl_id'] = kits_df['product_tmpl_id'].apply(lambda row: extract_sku(row[1]))\n",
    "kits_df = kits_df.explode('bom_line_ids')\n",
    "\n",
    "components_df = pd.DataFrame.from_records(components)\n",
    "components_df.loc[:,'product_id'] = components_df['product_id'].apply(lambda row: extract_sku(row[1]))\n",
    "\n",
    "# Obtener dataframe de paquetes con componentes\n",
    "packs_df = kits_df.merge(components_df, how='left', left_on='bom_line_ids', right_on='id')\n",
    "packs_df = (packs_df[['product_tmpl_id', 'product_id', 'product_qty']]\n",
    "            .rename(columns={\n",
    "                'product_tmpl_id': 'pack_id',\n",
    "                'product_id': 'component_id',\n",
    "                'product_qty': 'cantidad'\n",
    "                })\n",
    "            )\n",
    "\n",
    "# Ventas\n",
    "# Convertir columnas de lista a un solo valor\n",
    "sales_df = (pd.DataFrame.from_records(sales)\n",
    "            .explode('order_line'))\n",
    "\n",
    "# Convertir columnas de lista a un solo valor y obtener SKU\n",
    "order_lines_df = pd.DataFrame.from_records(order_lines)\n",
    "## Ignorar lineas vacias\n",
    "order_lines_df = order_lines_df[order_lines_df['product_id'] != False]\n",
    "order_lines_df.loc[:,'product_id'] = order_lines_df['product_id'].apply(lambda l: extract_sku(l[1]))\n",
    "\n",
    "# # Convertir paquetes en piezas individuales\n",
    "order_lines_df = order_lines_df.merge(packs_df, how='left', left_on='product_id', right_on='pack_id')\n",
    "order_lines_df.loc[:,'product_id'] = order_lines_df.apply(lambda row: row['product_id'] if pd.isna(row['pack_id']) else row['component_id'], axis=1)\n",
    "order_lines_df.loc[:,'cantidad'] = order_lines_df.apply(lambda row: row['product_uom_qty'] if pd.isna(row['pack_id']) else row['product_uom_qty']*row['cantidad'], axis=1)\n",
    "order_lines_df = order_lines_df.loc[:,['id', 'product_id', 'cantidad']]\n",
    "\n",
    "# Unir dataframes anteriores\n",
    "orders_df = sales_df.merge(order_lines_df, how='left', left_on='order_line', right_on='id')\n",
    "# Seleccionar y renombrar columnas\n",
    "orders_df = orders_df[['name', 'product_id', 'cantidad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff89e0",
   "metadata": {
    "id": "77ff89e0"
   },
   "source": [
    "## Pipeline\n",
    "El _pipeline_ a realizar consiste de los siguientes pasos:\n",
    "1. Obtener imagenes\n",
    "    1. Acceder a carpeta (posiblemente de Drive) y obtener todos los archivos de imagen.\n",
    "    2. Aplicar transformaciones a imagenes\n",
    "2. Aplicar modelo\n",
    "    - De cada producto detectado, determinar su SKU. (1)\n",
    "    - De la guía detectada, obtener el número de orden. (2)\n",
    "3. Separar por confianza en prediccion:\n",
    "    - Si la confianza es alta, cargar a ERP.\n",
    "    - Si la confianza es baja, enviar a carpeta para revisión. (3)\n",
    "\n",
    "(1) Utilizar modelo aparte  \n",
    "(2) Tratar de emplear API de Mercado Libre, en caso contrario descaragr reporte  \n",
    "(3) Agregar flujo de trabajo de Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4db8f9",
   "metadata": {
    "id": "5b4db8f9"
   },
   "source": [
    "### 1. Obtención de imágenes\n",
    "Estableceremos una conexión con la API de Drive y obtendremos el contenido de una carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ed8c0ad",
   "metadata": {
    "id": "6ed8c0ad"
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "## Obtencion de imagenes\n",
    "import io\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from PIL import Image\n",
    "## Transformacion de imagenes\n",
    "import os\n",
    "# Parametros\n",
    "CREDENTIALS = service_account.Credentials.from_service_account_file(\n",
    "   './secrets/access_keys_drive_api.json',\n",
    "   scopes=['https://www.googleapis.com/auth/drive']\n",
    "   )\n",
    "FOLDER_ID = '1H6miVnKLQh8AzWEWH1Yq2fL273XTvCFa'\n",
    "DEST_FOLDER = './datasets/downloaded_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa0bae",
   "metadata": {
    "id": "2afa0bae",
    "outputId": "5ec10664-0ebe-41c6-b16f-d6382001bddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando 701-0285686-8888270.jpg\n",
      "Download 100.\n"
     ]
    }
   ],
   "source": [
    "# Obtencion de imagenes\n",
    "## TO-DO: Logs con logger\n",
    "## TO-DO: Documentacion docstring\n",
    "# Obtener imagenes de archivo\n",
    "def get_images(folder_id: str, credentials):\n",
    "    try:\n",
    "        # Crear cliente\n",
    "        service = build(\"drive\", \"v3\", credentials=CREDENTIALS)\n",
    "        # Obtener lista de archivos\n",
    "        response = (service.files()\n",
    "                    .list(q=f\"trashed=false and '{folder_id}' in parents and mimeType = 'image/jpeg'\",\n",
    "                          spaces ='drive',\n",
    "                          fields='files(id, name)'\n",
    "                          )\n",
    "                    .execute()\n",
    "                    )\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"Ocurrio un error: {error}\")\n",
    "        response = {}\n",
    "    return response\n",
    "\n",
    "def download_images(response: dict, dest_folder: str):\n",
    "    try:\n",
    "        # Crear cliente\n",
    "        service = build(\"drive\", \"v3\", credentials=CREDENTIALS)\n",
    "        # Descargar cada imagen\n",
    "        for image in response.get('files', []):\n",
    "            print(f'Descargando {image['name']}')\n",
    "            request = service.files().get_media(fileId=image['id'])\n",
    "            file = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(file, request)\n",
    "            # Esperar a que este lista la descarga\n",
    "            done = False\n",
    "            while done is False:\n",
    "              status, done = downloader.next_chunk()\n",
    "              print(f\"Download {int(status.progress() * 100)}.\")\n",
    "            # Guardar en carpeta\n",
    "            with open(os.path.join(dest_folder, image['name']), 'wb') as img_file:\n",
    "              img_file.write(file.getbuffer())\n",
    "    except HttpError as error:\n",
    "        print(f\"Ocurrio un error: {error}\")\n",
    "\n",
    "\n",
    "download_images(get_images(FOLDER_ID, CREDENTIALS), DEST_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da42d92",
   "metadata": {
    "id": "4da42d92"
   },
   "outputs": [],
   "source": [
    "# Transformacion\n",
    "## ¿Sigue siendo necesario? YOLO ya reescala\n",
    "## TO-DO: ¿Cambiar a blanco y negro?\n",
    "def transform_images(origin_folder: str, width: int, height: int):\n",
    "    for file in os.listdir(origin_folder):\n",
    "        if not file.endswith('.jpg'):\n",
    "            continue\n",
    "        img = Image.open(f\"{origin_folder}/{file}\").convert('RGB')\n",
    "\n",
    "        # Rotar imagen para estar en vertical si esta en horizontal\n",
    "        if img.size[0] > img.size[1]:\n",
    "            img = img.rotate(-90, expand=True)\n",
    "        \n",
    "        # Reescalar imagenes\n",
    "        img = img.resize((width, height), resample=Image.LANCZOS)\n",
    "\n",
    "        # Save image\n",
    "        if not os.path.exists(f\"{origin_folder}/transformed\"):\n",
    "            os.mkdir(f\"{origin_folder}/transformed\")\n",
    "        img.save(f\"{origin_folder}/transformed/{file}\")\n",
    "        img.close()\n",
    "\n",
    "HEIGHT = 640\n",
    "WIDTH = int(3/4 * HEIGHT)\n",
    "transform_images(DEST_FOLDER, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2e8f8",
   "metadata": {},
   "source": [
    "### 2. Detección de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "from ultralytics import YOLO\n",
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Parametros\n",
    "ORIGIN_FOLDER = './datasets/downloaded_images/'\n",
    "MODEL = YOLO('./models/modelo_2025-11-13.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db3b1e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Guia', 1: 'Producto'}\n",
       " obb: ultralytics.engine.results.OBB object\n",
       " orig_img: array([[[202, 205, 209],\n",
       "         [204, 207, 211],\n",
       "         [203, 206, 210],\n",
       "         ...,\n",
       "         [148, 155, 158],\n",
       "         [148, 155, 158],\n",
       "         [148, 155, 158]],\n",
       " \n",
       "        [[203, 206, 210],\n",
       "         [205, 208, 212],\n",
       "         [205, 208, 212],\n",
       "         ...,\n",
       "         [149, 156, 159],\n",
       "         [149, 156, 159],\n",
       "         [149, 156, 159]],\n",
       " \n",
       "        [[203, 206, 210],\n",
       "         [205, 208, 212],\n",
       "         [204, 207, 211],\n",
       "         ...,\n",
       "         [150, 157, 160],\n",
       "         [150, 157, 160],\n",
       "         [150, 157, 160]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[209, 206, 208],\n",
       "         [209, 206, 208],\n",
       "         [208, 205, 207],\n",
       "         ...,\n",
       "         [126, 129, 133],\n",
       "         [125, 128, 132],\n",
       "         [125, 128, 132]],\n",
       " \n",
       "        [[209, 206, 208],\n",
       "         [209, 206, 208],\n",
       "         [208, 205, 207],\n",
       "         ...,\n",
       "         [126, 129, 133],\n",
       "         [125, 128, 132],\n",
       "         [125, 128, 132]],\n",
       " \n",
       "        [[209, 206, 208],\n",
       "         [209, 206, 208],\n",
       "         [208, 205, 207],\n",
       "         ...,\n",
       "         [126, 129, 133],\n",
       "         [125, 128, 132],\n",
       "         [125, 128, 132]]], dtype=uint8)\n",
       " orig_shape: (1920, 1440)\n",
       " path: 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\2000009651078123.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 11.195700000826037, 'inference': 441.2566999999399, 'postprocess': 3.5790000001725275},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Guia', 1: 'Producto'}\n",
       " obb: ultralytics.engine.results.OBB object\n",
       " orig_img: array([[[208, 203, 204],\n",
       "         [203, 198, 199],\n",
       "         [195, 190, 191],\n",
       "         ...,\n",
       "         [150, 155, 156],\n",
       "         [146, 151, 152],\n",
       "         [142, 147, 148]],\n",
       " \n",
       "        [[207, 202, 203],\n",
       "         [202, 197, 198],\n",
       "         [193, 188, 189],\n",
       "         ...,\n",
       "         [144, 149, 150],\n",
       "         [141, 146, 147],\n",
       "         [140, 145, 146]],\n",
       " \n",
       "        [[198, 193, 194],\n",
       "         [193, 188, 189],\n",
       "         [185, 180, 181],\n",
       "         ...,\n",
       "         [140, 145, 146],\n",
       "         [138, 143, 144],\n",
       "         [138, 143, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  82,  87],\n",
       "         [ 77,  83,  88],\n",
       "         [ 77,  83,  88],\n",
       "         ...,\n",
       "         [181, 182, 180],\n",
       "         [184, 185, 183],\n",
       "         [190, 191, 189]],\n",
       " \n",
       "        [[ 75,  81,  86],\n",
       "         [ 75,  81,  86],\n",
       "         [ 75,  81,  86],\n",
       "         ...,\n",
       "         [179, 180, 178],\n",
       "         [183, 184, 182],\n",
       "         [191, 192, 190]],\n",
       " \n",
       "        [[ 73,  79,  84],\n",
       "         [ 74,  80,  85],\n",
       "         [ 74,  80,  85],\n",
       "         ...,\n",
       "         [178, 179, 177],\n",
       "         [182, 183, 181],\n",
       "         [190, 191, 189]]], dtype=uint8)\n",
       " orig_shape: (1920, 1440)\n",
       " path: 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\2000009765719417.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 9.202799999911804, 'inference': 976.6425999987405, 'postprocess': 3.3496000032755546},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Guia', 1: 'Producto'}\n",
       " obb: ultralytics.engine.results.OBB object\n",
       " orig_img: array([[[139, 157, 164],\n",
       "         [134, 152, 159],\n",
       "         [129, 145, 152],\n",
       "         ...,\n",
       "         [104, 115, 123],\n",
       "         [100, 111, 119],\n",
       "         [ 85,  96, 104]],\n",
       " \n",
       "        [[137, 155, 162],\n",
       "         [135, 153, 160],\n",
       "         [135, 151, 158],\n",
       "         ...,\n",
       "         [106, 117, 125],\n",
       "         [102, 113, 121],\n",
       "         [ 92, 103, 111]],\n",
       " \n",
       "        [[130, 148, 155],\n",
       "         [132, 150, 157],\n",
       "         [136, 152, 159],\n",
       "         ...,\n",
       "         [105, 118, 126],\n",
       "         [101, 114, 122],\n",
       "         [ 97, 110, 118]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  46,  33],\n",
       "         [ 80,  72,  59],\n",
       "         [ 69,  61,  48],\n",
       "         ...,\n",
       "         [103, 109, 114],\n",
       "         [106, 112, 117],\n",
       "         [106, 112, 117]],\n",
       " \n",
       "        [[ 57,  49,  36],\n",
       "         [ 69,  61,  48],\n",
       "         [ 72,  64,  51],\n",
       "         ...,\n",
       "         [ 94, 100, 105],\n",
       "         [ 93,  99, 104],\n",
       "         [ 90,  96, 101]],\n",
       " \n",
       "        [[ 67,  59,  46],\n",
       "         [ 58,  50,  37],\n",
       "         [ 72,  64,  51],\n",
       "         ...,\n",
       "         [ 99, 105, 110],\n",
       "         [101, 107, 112],\n",
       "         [100, 106, 111]]], dtype=uint8)\n",
       " orig_shape: (1920, 1440)\n",
       " path: 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\701-0285686-8888270.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 8.126699998683762, 'inference': 213.63019999989774, 'postprocess': 2.9905000010330696}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa = MODEL.predict(ORIGIN_FOLDER)\n",
    "cosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a9aa3140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\2000009651078123.jpg',\n",
       "  'n_products': 1,\n",
       "  'tracking_id': '45707191070'},\n",
       " {'path': 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\2000009765719417.jpg',\n",
       "  'n_products': 2,\n",
       "  'tracking_id': '45769083914'},\n",
       " {'path': 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\701-0285686-8888270.jpg',\n",
       "  'n_products': 8,\n",
       "  'tracking_id': ''}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_objects(origin_folder: str, model):\n",
    "    # Obtener predicciones\n",
    "    preds = model.predict(origin_folder, verbose=False)\n",
    "    # Generar informacion de cada imagen\n",
    "    imgs_info = []\n",
    "    for pred in preds:\n",
    "        objs = pred.summary()\n",
    "        imgs_info.append({\n",
    "            'path': pred.path,\n",
    "            'products': [obj for obj in objs if obj['name'] == 'Producto'],\n",
    "            'guides': [obj for obj in objs if obj['name'] == 'Guia']\n",
    "        })\n",
    "    # for i, img in enumerate(os.listdir(origin_folder)):\n",
    "    #     if not img.endswith('.jpg'):\n",
    "    #         continue\n",
    "    #     objs = preds[i].summary()\n",
    "    #     imgs_info.append({\n",
    "    #         'img_path': origin_folder + img,\n",
    "    #         'products': [obj for obj in objs if obj['name'] == 'Producto'],\n",
    "    #         'guides': [obj for obj in objs if obj['name'] == 'Guia']\n",
    "    #     })\n",
    "    return imgs_info\n",
    "\n",
    "def process_products(products: list):\n",
    "    # Por el momento solo regresa el numero de productos que pase cierto umbral\n",
    "    treeshold = 0.7\n",
    "    # Cantidad de productos con seguridad mayor al treeshold\n",
    "    n = len([product for product in products if product['confidence']>treeshold])\n",
    "    return n\n",
    "\n",
    "def region_properties(box: list|tuple) -> tuple:\n",
    "    # Esquinas de la region\n",
    "    quad = (box['x4'], box['y4'], box['x1'], box['y1'], box['x2'], box['y2'], box['x3'], box['y3'])\n",
    "    # Largo y ancho\n",
    "    width = ((box['x1']-box['x2'])**2 + (box['y1']-box['y2'])**2)**0.5\n",
    "    height = ((box['x3']-box['x2'])**2 + (box['y3']-box['y2'])**2)**0.5\n",
    "    if width > height:\n",
    "        width, height = height, width\n",
    "    # Area\n",
    "    area = width*height\n",
    "    # Diccionario con propiedades del area\n",
    "    props = {'quad': quad, 'width': int(width), 'height': int(height), 'area': area}\n",
    "    return props\n",
    "\n",
    "def process_guides(guides: list, img_path: str):\n",
    "    # Filtrar guia con area mas grande\n",
    "    regions = [region_properties(guide['box']) for guide in guides]\n",
    "    idx = np.argmax([box['area'] for box in regions])\n",
    "    region = regions[idx]\n",
    "\n",
    "    # Obtener region de la guia\n",
    "    with Image.open(img_path) as img:\n",
    "        guide_img = img.transform((region['width'], region['height']), Image.QUAD, region['quad'])\n",
    "\n",
    "    # Abrir imagen y buscar codigo de barras\n",
    "    code_list = [code.data.decode() for code in decode(guide_img) if code.type=='CODE128']\n",
    "    track_ids = [code for code in code_list if len(code)==11]\n",
    "    track_id = track_ids[0] if track_ids else ''\n",
    "    return track_id\n",
    "\n",
    "def process_image(imgs_info: list):\n",
    "    for info in imgs_info:\n",
    "        info['n_products'] = process_products(info.pop('products', []))\n",
    "        info['tracking_id'] = process_guides(info.pop('guides', []), info['path'])\n",
    "    return imgs_info\n",
    "\n",
    "imgs_info = process_image(detect_objects(ORIGIN_FOLDER, MODEL))\n",
    "imgs_info\n",
    "#print(process_products(imgs_info['2000009651078123.jpg']['products']))\n",
    "#print(process_guides(imgs_info['2000009651078123.jpg']['img_path'], imgs_info['2000009651078123.jpg']['guides']))\n",
    "#MODEL.predict(imgs_info['2000009651078123.jpg']['img_path'])[0].show()\n",
    "#process_guides(imgs_info['2000009651078123.jpg']['img_path'], imgs_info['2000009651078123.jpg']['guides'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af902ce",
   "metadata": {
    "id": "7af902ce"
   },
   "source": [
    "### 3. Cargar imagen a ERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "67b18430",
   "metadata": {
    "id": "67b18430",
    "outputId": "9794ad36-565c-4560-882b-d61634120f21"
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import xmlrpc.client\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "TRACK_FILE = './datasets/tracks_id.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40680ae0",
   "metadata": {
    "id": "40680ae0"
   },
   "outputs": [],
   "source": [
    "# Información de acceso\n",
    "with open('./secrets/access_keys_test.json') as file:\n",
    "    db_info = json.load(file)\n",
    "\n",
    "# Autenticación\n",
    "common = xmlrpc.client.ServerProxy('{}/xmlrpc/2/common'.format(db_info['url']))\n",
    "uid = common.authenticate(db_info['db'], db_info['user'], db_info['password'], {})\n",
    "# Conexión con base de datos\n",
    "models = xmlrpc.client.ServerProxy('{}/xmlrpc/2/object'.format(db_info[\"url\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fff6a63a",
   "metadata": {
    "id": "fff6a63a",
    "outputId": "1a9c95f8-c929-4b52-c904-e675de498a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio de funcion: get_sale_order\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    110\u001b[39m ordenes = {\u001b[33m'\u001b[39m\u001b[33m701-0285686-8888270\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mimg_path\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m./downloaded_images/701-0285686-8888270.jpg\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m    111\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m701-0573713-1097802\u001b[39m\u001b[33m'\u001b[39m:{\u001b[33m'\u001b[39m\u001b[33mimg_path\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m./downloaded_images/701-0573713-1097802.jpg\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m    112\u001b[39m            }\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m#get_sale_order(get_tracking_info(imgs_info, TRACK_FILE))\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m#create_message(upload_image(get_sale_order(ordenes)))\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m upload_image(\u001b[43mget_sale_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordenes\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mdebug.<locals>.wrapper\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInicio de funcion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFin de funcion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mget_sale_order\u001b[39m\u001b[34m(imgs_info)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Peticion a ERP de ids\u001b[39;00m\n\u001b[32m     37\u001b[39m fields = [\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m order_names = [\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43morder_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m imgs_info]\n\u001b[32m     39\u001b[39m filters = [[(\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33min\u001b[39m\u001b[33m\"\u001b[39m, order_names)]]\n\u001b[32m     40\u001b[39m order_info = models.execute_kw(db_info[\u001b[33m\"\u001b[39m\u001b[33mdb\u001b[39m\u001b[33m\"\u001b[39m], uid, db_info[\u001b[33m'\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msale.order\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msearch_read\u001b[39m\u001b[33m'\u001b[39m, filters, {\u001b[33m'\u001b[39m\u001b[33mfields\u001b[39m\u001b[33m'\u001b[39m: fields})\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# TO-DO: Funciones de pipeline\n",
    "# Decorador para debugg\n",
    "def debug(func):\n",
    "    def wrapper(*args):\n",
    "        print(f'Inicio de funcion: {func.__name__}')\n",
    "        y = func(*args)\n",
    "        print(f'Fin de funcion: {func.__name__}')\n",
    "        return y\n",
    "    return wrapper\n",
    "\n",
    "# Agregar informacion de seguimiento\n",
    "@debug\n",
    "def get_tracking_info(imgs_info: list, tracking_file: str) -> list:\n",
    "    \"\"\"\n",
    "    imgs_info: Lista de diccionarios con propiedades\n",
    "        - tracking_id: numero de rastreo del pedido\n",
    "    \"\"\"\n",
    "    track_order = {}\n",
    "    with open(tracking_file) as file:\n",
    "        # Omitir encabezado\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            track_id, order_id = line.strip().split(',')\n",
    "            track_order[track_id] = order_id\n",
    "    for info in imgs_info:\n",
    "        info['order_name'] = track_order.get(info['tracking_id'], '')\n",
    "    return imgs_info\n",
    "\n",
    "# Obtener id de venta\n",
    "@debug\n",
    "def get_sale_order(imgs_info: list) -> list:\n",
    "    \"\"\"\n",
    "    imgs_info: Lista de diccionarios con propiedades\n",
    "        - order_name: Numero de venta\n",
    "    \"\"\"\n",
    "    # Peticion a ERP de ids\n",
    "    fields = ['name']\n",
    "    order_names = [info['order_name'] for info in imgs_info]\n",
    "    filters = [[(\"name\", \"in\", order_names)]]\n",
    "    order_info = models.execute_kw(db_info[\"db\"], uid, db_info['password'], 'sale.order', 'search_read', filters, {'fields': fields})\n",
    "\n",
    "    # Crear diccionario de numero de venta - id\n",
    "    order_id = {info['name']: info['id'] for info in order_info}\n",
    "\n",
    "    # Agregar id\n",
    "    for info in imgs_info:\n",
    "        info['order_id'] = order_id.get(info['order_name'], '')\n",
    "\n",
    "    return imgs_info\n",
    "\n",
    "# Cargar archivo\n",
    "@debug\n",
    "def upload_image(imgs_info: list) -> list:\n",
    "    \"\"\"\n",
    "    imgs_info: Lista de diccionarios con propiedades\n",
    "        - order_id: ID de orden en ERP\n",
    "        - path: Ruta de acceso a imagen\n",
    "    \"\"\"\n",
    "    # Preparar lista de archivos a subir\n",
    "    records = []\n",
    "    for info in imgs_info:\n",
    "        if not info['order_id']:\n",
    "            continue\n",
    "        vals = {\n",
    "            'name': os.path.basename(info['path']), # Nombre de archivo\n",
    "            'res_model': 'sale.order',\n",
    "            'res_id': info['order_id']\n",
    "        }\n",
    "        with open(info['path'], \"rb\") as img:\n",
    "            vals['datas'] = base64.b64encode(img.read()).decode('utf-8')\n",
    "        records.append(vals)\n",
    "\n",
    "    # Crear registro de archivo\n",
    "    records_id = models.execute_kw(db_info[\"db\"], uid, db_info['password'],\n",
    "                                   'ir.attachment', 'create',\n",
    "                                   [records])\n",
    "    # IDs de archivo\n",
    "    files_ids = {}\n",
    "    for i, id in enumerate(records_id):\n",
    "        files_ids[records['name']] = id\n",
    "    for info in imgs_info:\n",
    "        info['file_id'] = files_ids.get(os.path.basename(info['path']),'')\n",
    "    return imgs_info\n",
    "\n",
    "# Crear mensaje\n",
    "@debug\n",
    "def create_message(orders: dict) -> dict:\n",
    "    \"\"\"\n",
    "    orders: Diccionario de 'objetos' (diccionarios) de orden con propiedades\n",
    "        - id: ID de orden en ERP\n",
    "        - img_path: Ruta de acceso a imagen\n",
    "        - file_id: ID de imagen en ERP\n",
    "    \"\"\"\n",
    "    # Preparar lista de mensajes a crear\n",
    "    records = []\n",
    "    for name, info in orders.items():\n",
    "        msg = {\n",
    "            'model': 'sale.order',\n",
    "            'res_id': info['id'],\n",
    "            'author_id': uid,\n",
    "            'subtype_id': 2,\n",
    "            'body': f'Mensaje creado desde API. Venta {name}',\n",
    "            'attachment_ids': [info['file_id']]\n",
    "        }\n",
    "        records.append(msg)\n",
    "    # Crear mensajes en ERP\n",
    "    models.execute_kw(db_info['db'], uid, db_info['password'], 'mail.message', 'create',\n",
    "                      [records])\n",
    "\n",
    "ordenes = {'701-0285686-8888270': {'img_path': './downloaded_images/701-0285686-8888270.jpg'},\n",
    "            '701-0573713-1097802':{'img_path': './downloaded_images/701-0573713-1097802.jpg'}\n",
    "           }\n",
    "#get_sale_order(get_tracking_info(imgs_info, TRACK_FILE))\n",
    "#create_message(upload_image(get_sale_order(ordenes)))\n",
    "upload_image(get_sale_order(ordenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e404e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'path': 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\2000009651078123.jpg', 'n_products': 1, 'tracking_id': '45707191070'}, {'path': 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\2000009765719417.jpg', 'n_products': 2, 'tracking_id': '45769083914'}, {'path': 'd:\\\\alan_\\\\Documents\\\\Alan\\\\Facultad\\\\Tetramestre 4\\\\Procesamiento y Clasificacion de Datos\\\\PIA\\\\datasets\\\\downloaded_images\\\\701-0285686-8888270.jpg', 'n_products': 8, 'tracking_id': ''}]\n",
      "Verdadero\n",
      "Verdadero\n",
      "Salio esto .\n"
     ]
    }
   ],
   "source": [
    "print(imgs_info)\n",
    "for info in imgs_info:\n",
    "    if info['tracking_id']:\n",
    "        print('Verdadero')\n",
    "    else:\n",
    "        print(f'Salio esto {info['tracking_id']}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9d2ef",
   "metadata": {
    "id": "fef9d2ef",
    "outputId": "82118cc2-1594-4b86-de44-a6bf18112460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 128733, 'name': '701-0285686-8888270', 'order_line': [181534]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener ventas asociadas\n",
    "## https://www.odoo.com/es/forum/ayuda-1/odoo-14-external-api-how-to-add-notescommentsmessageslogs-in-contact-194917\n",
    "# fields = ['name', 'order_line']\n",
    "# filters = [[(\"name\", \"=\", '701-0285686-8888270')]]\n",
    "# sales = models.execute_kw(db_info['db'], uid, db_info['password'],\n",
    "#                           'sale.order',\n",
    "#                           'search_read',\n",
    "#                           filters,\n",
    "#                           {'fields': fields})\n",
    "# sales\n",
    "#info = models.execute_kw(db_info['db'], uid, db_info['password'], 'mail.message', 'fields_get', [], {'attributes': ['string', 'help', 'type']})\n",
    "#list(info.keys())[100:]\n",
    "# models.execute_kw(db_info['db'], uid, db_info['password'], 'mail.message', 'create',\n",
    "#                   [{'model': 'sale.order',\n",
    "#                     'res_id': id,\n",
    "#                     'body': \"This note was made using the API 2\",\n",
    "#                     'author_id': uid,\n",
    "#                     'create_date': datetimestring,\n",
    "#                     'date': datetimestring,\n",
    "#                     'write_date': datetimestring\n",
    "#                     'attachment_ids':[]}]\n",
    "#                     )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
